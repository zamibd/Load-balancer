groups:
  - name: haproxy_alerts
    rules:
      # High error rate
      - alert: HAProxyHighErrorRate
        expr: rate(haproxy_frontend_http_responses_total{code="5xx"}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "HAProxy high 5xx error rate"
          description: "HAProxy is returning more than 10% 5xx errors"

      # Backend down
      - alert: HAProxyBackendDown
        expr: haproxy_backend_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "HAProxy backend {{ $labels.proxy }} is down"
          description: "Backend {{ $labels.proxy }} has been down for more than 1 minute"

      # High connection rate
      - alert: HAProxyHighConnectionRate
        expr: rate(haproxy_frontend_connections_total[5m]) > 1000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "HAProxy high connection rate"
          description: "Connection rate is above 1000/s for 5 minutes"

      # Server response time
      - alert: HAProxySlowResponse
        expr: haproxy_backend_response_time_average_seconds > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "HAProxy slow backend response"
          description: "Backend {{ $labels.proxy }} average response time > 2s"

      # DoT Frontend down
      - alert: HAProxyDoTDown
        expr: haproxy_frontend_status{proxy="ft_dot"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "HAProxy DoT frontend is down"
          description: "DNS over TLS frontend has been down for more than 1 minute"

  - name: infrastructure_alerts
    rules:
      # Container down
      - alert: ContainerDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Container {{ $labels.job }} is down"
          description: "Container {{ $labels.job }} has been down for more than 1 minute"

  - name: valkey_alerts
    rules:
      # Valkey down (using redis_exporter metrics)
      - alert: ValkeyDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Valkey is down"
          description: "Valkey has been unreachable for more than 1 minute"

      # High memory usage
      - alert: ValkeyHighMemory
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Valkey high memory usage"
          description: "Valkey memory usage is above 90%"

      # Too many connected clients
      - alert: ValkeyTooManyConnections
        expr: redis_connected_clients > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Valkey has too many connections"
          description: "Valkey has more than 100 connected clients"

      # High command latency
      - alert: ValkeyHighLatency
        expr: rate(redis_commands_duration_seconds_total[5m]) / rate(redis_commands_processed_total[5m]) > 0.01
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Valkey high command latency"
          description: "Valkey average command latency is above 10ms"

  - name: routedns_alerts
    rules:
      # RouteDNS backend unreachable
      - alert: RouteDNSBackendDown
        expr: haproxy_backend_active_servers{proxy="bk_dot_upstream"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "RouteDNS backend is down"
          description: "All RouteDNS servers are unreachable"
